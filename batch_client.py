"""
APIæµ‹è¯•å®¢æˆ·ç«¯ç¤ºä¾‹

åŠŸèƒ½: æµ‹è¯•åŒæ­¥ã€å¤šè¯´è¯äººã€å¼‚æ­¥å’Œå¥åº·æ£€æŸ¥ç­‰åŠŸèƒ½çš„å®¢æˆ·ç«¯ä»£ç ã€‚

ä½¿ç”¨ç¤ºä¾‹:
    # ç¡®ä¿æœåŠ¡ç«¯å·²å¯åŠ¨: python run_server.py
    # è¿è¡Œå•æ¬¡åŒæ­¥æµ‹è¯•
    python client_test.py --mode sync
    # è¿è¡Œå¹¶å‘æµ‹è¯• (100ä¸ªè¯·æ±‚ï¼Œ10ä¸ªå¹¶å‘çº¿ç¨‹)
    python client_test.py --mode batch --batch-size 100 --max-workers 10
    python client_test.py --mode async
"""
import requests
import time
import json
import argparse
import os
import concurrent.futures
from pathlib import Path

# ==============================================================================
# æ‰¹é‡å¹¶å‘æµ‹è¯•å‡½æ•° (å·²ä¿®æ”¹ä¸ºé€‚åˆå‹æµ‹çš„é€»è¾‘)
# ==============================================================================

def test_sync_single_speaker_batch(api_url: str, batch_size: int = 100, max_workers: int = 10):
    """æµ‹è¯•åŒæ­¥ç”Ÿæˆ - å•è¯´è¯äººæ‰¹é‡å¹¶å‘è¯·æ±‚ (ç”¨äºå‹æµ‹)"""
    print("\n" + "=" * 60)
    print(f"æµ‹è¯•: åŒæ­¥ç”Ÿæˆ - å•è¯´è¯äººæ‰¹é‡å¹¶å‘ ({batch_size}ä¸ªè¯·æ±‚)")
    print("=" * 60)

    # å‡†å¤‡æ–‡ä»¶
    audio_file = "example/audios/female_mandarin.wav"
    if not Path(audio_file).exists():
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶ {audio_file}")
        print("è¯·ç¡®ä¿ 'example/audios/female_mandarin.wav' å­˜åœ¨")
        return

    # ä½¿ç”¨å›ºå®šçš„å¯¹è¯å†…å®¹ï¼Œä»¥ç¡®ä¿æµ‹è¯•çš„æ˜¯ç³»ç»Ÿååé‡
    DIALOGUE_TEXT = '[S1]å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ä»Šå¤©çš„èŠ‚ç›®ã€‚ä»Šå¤©æˆ‘ä»¬è¦èŠä¸€èŠäººå·¥æ™ºèƒ½çš„æœ€æ–°è¿›å±•ã€‚'
    PROMPT_TEXTS = json.dumps(["å–œæ¬¢æ”€å²©ã€å¾’æ­¥ã€æ»‘é›ªçš„è¯­è¨€çˆ±å¥½è€…ã€‚"]) # ä½¿ç”¨ json.dumps ä¿è¯æ ¼å¼æ­£ç¡®

    def single_request(request_id: int):
        """å•ä¸ªè¯·æ±‚å‡½æ•°"""
        request_start = time.time()

        # æ¯ä¸ªè¯·æ±‚éƒ½éœ€è¦ç‹¬ç«‹çš„æ–‡ä»¶å¯¹è±¡
        # æ³¨æ„ï¼šåœ¨å¹¶å‘ç¯å¢ƒä¸­ï¼Œå¿…é¡»åœ¨æ¯æ¬¡è¯·æ±‚æ—¶é‡æ–°æ‰“å¼€æ–‡ä»¶ï¼Œä»¥ä¿è¯çº¿ç¨‹å®‰å…¨
        with open(audio_file, 'rb') as audio_fp:
            
            # files å¿…é¡»æ˜¯å­—å…¸ {å­—æ®µå: æ–‡ä»¶å¯¹è±¡}
            files = {
                'prompt_audio': audio_fp
            }
            # data å¿…é¡»æ˜¯å­—å…¸ {å­—æ®µå: å€¼}ï¼Œæˆ–è€…å…ƒç»„åˆ—è¡¨ [(k, v), ...]
            # è¿™é‡Œçš„ prompt_texts å¿…é¡»æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯åˆ—è¡¨
            data = {
                'prompt_texts': PROMPT_TEXTS, # å…³é”®ï¼šè¿™é‡Œç›´æ¥ä½¿ç”¨ JSON å­—ç¬¦ä¸²
                'dialogue_text': DIALOGUE_TEXT,
                # 'seed': str(1988 + request_id),  # ä½¿ç”¨ä¸åŒçš„seed
                'save_output': 'False'
            }

            try:
                # å‘é€ multipart/form-data è¯·æ±‚
                response = requests.post(f"{api_url}/generate", files=files, data=data, timeout=300)
                response.raise_for_status()
                if response.headers.get('content-type') == 'application/json':
                    response_size = len(response.text.encode('utf-8'))
                else:
                    response_size = len(response.content)
                # ä¸ä¿å­˜å†…å®¹ï¼Œä»¥æœ€å°åŒ– I/O å¸¦æ¥çš„å½±å“
                # output_path = f"api/outputs/batch_test/test_batch_{request_id:03d}.wav"
                # Path(output_path).parent.mkdir(parents=True, exist_ok=True)
                # with open(output_path, 'wb') as f:
                #     f.write(response.content)

                elapsed = time.time() - request_start
                return {
                    'request_id': request_id,
                    'success': True,
                    'duration': elapsed,
                    'response_size': len(response.content)
                }

            except Exception as e:
                elapsed = time.time() - request_start
                return {
                    'request_id': request_id,
                    'success': False,
                    'duration': elapsed,
                    'error': str(e)
                }

    print(f"ğŸš€ å¯åŠ¨ {batch_size} ä¸ªå¹¶å‘è¯·æ±‚ (æœ€å¤§å¹¶å‘: {max_workers})...")
    batch_start = time.time()

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œ
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰è¯·æ±‚
        future_to_id = {executor.submit(single_request, i+1): i+1 for i in range(batch_size)}

        # æ”¶é›†ç»“æœ
        completed_count = 0
        for future in concurrent.futures.as_completed(future_to_id):
            result = future.result()
            results.append(result)
            completed_count += 1

            # å®æ—¶æ˜¾ç¤ºè¿›åº¦
            if completed_count % (batch_size // 10 or 1) == 0 or completed_count == batch_size:
                success_count = sum(1 for r in results if r['success'])
                print(f"ğŸ“Š è¿›åº¦: {completed_count}/{batch_size} å®Œæˆ (æˆåŠŸ: {success_count})")

    batch_elapsed = time.time() - batch_start

    # ç»Ÿè®¡ç»“æœ
    successful_results = [r for r in results if r['success']]
    failed_results = [r for r in results if not r['success']]

    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ‰¹é‡å¹¶å‘æµ‹è¯•ç»“æœç»Ÿè®¡")
    print("=" * 60)
    print(f"æ€»è¯·æ±‚æ•°: {batch_size}")
    print(f"æˆåŠŸè¯·æ±‚: {len(successful_results)}")
    print(f"å¤±è´¥è¯·æ±‚: {len(failed_results)}")
    print(f"æˆåŠŸç‡: {len(successful_results)/batch_size*100:.1f}%")
    print(f"æ‰¹æ¬¡æ€»è€—æ—¶: {batch_elapsed:.2f}ç§’")

    if successful_results:
        durations = [r['duration'] for r in successful_results]
        response_sizes = [r['response_size'] for r in successful_results]

        # è®¡ç®— P95 å»¶è¿Ÿ
        durations.sort()
        p95_index = int(len(durations) * 0.95) - 1
        p95_latency = durations[p95_index]
        
        print(f"\nâ±ï¸  å“åº”æ—¶é—´ç»Ÿè®¡:")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {sum(durations)/len(durations):.2f}ç§’")
        print(f"   æœ€å¿«å“åº”: {min(durations):.2f}ç§’")
        print(f"   æœ€æ…¢å“åº”: {max(durations):.2f}ç§’")
        print(f"   P95 å“åº”æ—¶é—´: {p95_latency:.2f}ç§’")
        print(f"   å“åº”æ—¶é—´ä¸­ä½æ•° (P50): {durations[len(durations)//2]:.2f}ç§’")

        print(f"\nğŸš€ ååé‡ç»Ÿè®¡:")
        print(f"   å®é™…å¹¶å‘åº¦: {max_workers}")
        print(f"   å¹³å‡ååé‡: {len(successful_results)/batch_elapsed:.2f} è¯·æ±‚/ç§’")
        print(f"   æ€»æ•°æ®é‡: {sum(response_sizes)/1024/1024:.1f} MB")

    # æ˜¾ç¤ºå¤±è´¥çš„è¯·æ±‚
    if failed_results:
        print(f"\nâŒ å¤±è´¥è¯·æ±‚è¯¦æƒ…:")
        for result in failed_results[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªå¤±è´¥è¯·æ±‚
            print(f"   è¯·æ±‚ {result['request_id']}: {result['error']}")
        if len(failed_results) > 10:
            print(f"   ... è¿˜æœ‰ {len(failed_results)-10} ä¸ªå¤±è´¥è¯·æ±‚")

    return {
        'total_requests': batch_size,
        'successful': len(successful_results),
        'failed': len(failed_results),
        'batch_duration': batch_elapsed,
        'success_rate': len(successful_results)/batch_size*100,
        'avg_response_time': sum(r['duration'] for r in successful_results)/len(successful_results) if successful_results else 0,
        'throughput': len(successful_results)/batch_elapsed if successful_results else 0
    }

# ==============================================================================
# å…¶ä»–ä¸å˜çš„å‡½æ•° (test_sync_single_speaker, test_sync_multi_speaker, test_async, test_health)
# ... (ä¸ºèŠ‚çœç¯‡å¹…çœç•¥ï¼Œè¯·ä½¿ç”¨æ‚¨æä¾›çš„åŸæ–‡ä»¶ä¸­çš„ä»£ç ) ...
# ==============================================================================


def main():
    parser = argparse.ArgumentParser(description="APIæµ‹è¯•å®¢æˆ·ç«¯")
    parser.add_argument(
        "--url",
        type=str,
        default="http://localhost:8000",
        help="APIæœåŠ¡åœ°å€ï¼ˆé»˜è®¤: http://localhost:8000ï¼‰"
    )
    parser.add_argument(
        "--mode",
        type=str,
        # å¢åŠ  'batch' æ¨¡å¼é€‰é¡¹
        choices=["health", "sync", "async", "batch", "all"], 
        default="all",
        help="æµ‹è¯•æ¨¡å¼ï¼ˆé»˜è®¤: allï¼‰"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=100, # é»˜è®¤è®¾ç½®ä¸º100ä¸ªè¯·æ±‚
        help="æ‰¹é‡æµ‹è¯•è¯·æ±‚æ•°é‡ï¼ˆé»˜è®¤: 100ï¼‰"
    )
    parser.add_argument(
        "--max-workers",
        type=int,
        default=10, # é»˜è®¤è®¾ç½®ä¸º10ä¸ªå¹¶å‘
        help="æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 10ï¼‰"
    )

    args = parser.parse_args()

    print("SoulX-Podcast API æµ‹è¯•å®¢æˆ·ç«¯")
    print(f"APIåœ°å€: {args.url}")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path("api/outputs").mkdir(parents=True, exist_ok=True)
    Path("api/outputs/batch_test").mkdir(parents=True, exist_ok=True) # ç¡®ä¿æ‰¹é‡æµ‹è¯•ç›®å½•å­˜åœ¨


    # æ–°å¢æ‰¹é‡å¹¶å‘æµ‹è¯•æ¨¡å¼
    if args.mode in ["batch", "all"]:
        # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥è°ƒç”¨äº†æˆ‘ä»¬ä¿®æ”¹åçš„å¹¶å‘å‡½æ•°
        test_sync_single_speaker_batch(args.url, args.batch_size, args.max_workers) 


    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()